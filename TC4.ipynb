{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nunesjoab/tech_challenge_4/blob/main/TC4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação das bibliotecas"
      ],
      "metadata": {
        "id": "pPkMaRpTKeol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "DlVa47Ro2LXV",
        "outputId": "dbfe5260-bb83-4986-e33b-0b99fb1db9e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepface in /usr/local/lib/python3.11/dist-packages (0.0.93)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.2.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.1)\n",
            "Requirement already satisfied: flask-cors>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (6.0.1)\n",
            "Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.0.0)\n",
            "Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.0.17)\n",
            "Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.7.0)\n",
            "Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (23.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.5.1)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (4.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.7.9)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.25.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting numpy<2.3.0,>=2 (from opencv-python-headless)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
            "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
            "Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.0.2 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "4cfa37436cdb469bbf87528788abf6dc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install deepface\n",
        "!pip install keras\n",
        "!pip install opencv-python-headless tf-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variáveis de entreda e saída"
      ],
      "metadata": {
        "id": "FhSnK7FKKmdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Ruap6uigk4",
        "outputId": "78bcfac4-cdf5-449a-e177-fdac6d2afa5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path=\"/content/drive/MyDrive/Colab Notebooks/Unlocking Facial Recognition_ Diverse Activities Analysis.mp4\"\n",
        "output_video_path_emotions=\"/content/output_video_emotions.mp4\"\n",
        "output_video_path_pose=\"/content/output_video_pose.mp4\"\n",
        "output_text_path=\"/content/output_text.txt\"\n",
        "output_audio_path=\"/content/output_audio.wav\"\n",
        "output_text_path_sentences=\"/content/output_text_sentences.txt\"\n",
        "output_text_path_punctuation=\"/content/output_text_punctuation.txt\"\n",
        "output_text_path_summarization=\"/content/output_text_summarization.txt\"\n",
        "output_text_path_video_emotions=\"/content/output_text_path_video_emotions.txt\"\n",
        "output_text_path_video_emotions_summarization=\"/content/output_text_path_video_emotions_summarization.txt\""
      ],
      "metadata": {
        "id": "pZDOJ6RpGXx_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecção de emoção"
      ],
      "metadata": {
        "id": "dbCx2eGjKa2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def detect_emotions(video_path, output_path):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  if not cap.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "    return\n",
        "\n",
        "  width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "  out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "  dominant_emotions = []\n",
        "  for _ in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    results = DeepFace.analyze(\n",
        "            frame,\n",
        "            actions=['emotion'],\n",
        "            enforce_detection=False,\n",
        "            detector_backend='opencv',\n",
        "            align=False\n",
        "        )\n",
        "\n",
        "        # Caso retorne um único dicionário, converte para lista\n",
        "    if isinstance(results, dict):\n",
        "        results = [results]\n",
        "\n",
        "\n",
        "    for face in results:\n",
        "      x = face['region']['x']\n",
        "      y = face['region']['y']\n",
        "      w = face['region']['w']\n",
        "      h = face['region']['h']\n",
        "\n",
        "      dominant_emotion = face['dominant_emotion']\n",
        "      dominant_emotions.append({\n",
        "          \"frame\": _,\n",
        "          \"emotion\": dominant_emotion\n",
        "      })\n",
        "\n",
        "\n",
        "      cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "      cv2.putText(frame, dominant_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "  cap.release()\n",
        "  out.release()\n",
        "  # cv2.destroyAllWindows()\n",
        "\n",
        "    # with open(output_text_path_video_emotions, \"w\", encoding=\"utf-8\") as f:\n",
        "    # for item in dominant_emotions:\n",
        "    #     f.write(f\"At frame {item['frame']}, a person expressed {item['emotion']}.\")\n",
        "\n",
        "  # Após processar todos os frames:\n",
        "  emotion_counts = {}\n",
        "  emotion_sequences = []\n",
        "  current_emotion = None\n",
        "  start_frame = 0\n",
        "\n",
        "  for item in dominant_emotions:\n",
        "      frame = item['frame']\n",
        "      emotion = item['emotion']\n",
        "\n",
        "      # Contabilizar emoções\n",
        "      if emotion not in emotion_counts:\n",
        "          emotion_counts[emotion] = 0\n",
        "      emotion_counts[emotion] += 1\n",
        "\n",
        "      # Detectar mudanças de emoção para criar sequências\n",
        "      if emotion != current_emotion:\n",
        "          if current_emotion is not None:\n",
        "              emotion_sequences.append({\n",
        "                  'emotion': current_emotion,\n",
        "                  'start_frame': start_frame,\n",
        "                  'end_frame': frame - 1,\n",
        "                  'duration': frame - start_frame\n",
        "              })\n",
        "          current_emotion = emotion\n",
        "          start_frame = frame\n",
        "\n",
        "  # Adicionar a última sequência\n",
        "  if current_emotion is not None:\n",
        "      emotion_sequences.append({\n",
        "          'emotion': current_emotion,\n",
        "          'start_frame': start_frame,\n",
        "          'end_frame': len(dominant_emotions) - 1,\n",
        "          'duration': len(dominant_emotions) - start_frame\n",
        "      })\n",
        "\n",
        "  # Escrever resumo estruturado\n",
        "  with open(output_text_path_video_emotions, \"w\", encoding=\"utf-8\") as f:\n",
        "      # Resumo geral\n",
        "      f.write(\"EMOTION ANALYSIS SUMMARY\\n\\n\")\n",
        "      f.write(\"Overall emotion distribution:\\n\")\n",
        "      for emotion, count in sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "          percentage = (count / len(dominant_emotions)) * 100\n",
        "          f.write(f\"- {emotion}: {count} frames ({percentage:.1f}%)\\n\")\n",
        "\n",
        "      f.write(\"\\nEmotion sequences:\\n\")\n",
        "      for i, seq in enumerate(emotion_sequences):\n",
        "          if seq['duration'] > 10:  # Filtrar sequências muito curtas\n",
        "              f.write(f\"Sequence {i+1}: {seq['emotion']} from frame {seq['start_frame']} to {seq['end_frame']} (duration: {seq['duration']} frames)\\n\")\n",
        "\n",
        "      f.write(\"\\nDetailed frame analysis:\\n\")\n",
        "      # Agrupar por grupos de 30 frames para reduzir verbosidade\n",
        "      for i in range(0, len(dominant_emotions), 30):\n",
        "          group = dominant_emotions[i:i+30]\n",
        "          main_emotion = max(set([g['emotion'] for g in group]), key=[g['emotion'] for g in group].count)\n",
        "          f.write(f\"From frame {group[0]['frame']} to frame {group[-1]['frame']}: predominantly {main_emotion}\\n\")\n",
        "\n",
        "\n",
        "detect_emotions(input_video_path, output_video_path_emotions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va6WjHur4rxV",
        "outputId": "110b1b76-7936-434c-cb6c-351c9a4908f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing frames: 100%|██████████| 3326/3326 [27:54<00:00,  1.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecçaão de Pose"
      ],
      "metadata": {
        "id": "WJWKcBuSKOhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "zIly2EcrEgCr",
        "outputId": "b7a7a09b-d761-4ee3-ca9f-cea3f437abec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ce80e8ff98e149159341754de3907dfa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def detect_pose(video_path, output_path):\n",
        "  mp_drawing = mp.solutions.drawing_utils\n",
        "  mp_pose = mp.solutions.pose\n",
        "  pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  if not cap.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "    return\n",
        "\n",
        "  width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "  out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "  for _ in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    results = pose.process(frame_rgb)\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "      mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "\n",
        "  cap.release()\n",
        "  out.release()\n",
        "  # cv2.destroyAllWindows()\n",
        "\n",
        "detect_pose(input_video_path, output_video_path_pose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOcvMBF0E2eQ",
        "outputId": "1f946177-5bb5-4e0b-e541-f3403c8a5154"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing frames: 100%|██████████| 3326/3326 [03:42<00:00, 14.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcrição de áudio"
      ],
      "metadata": {
        "id": "Gh7Zcy-JLCiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy speechrecognition pydub\n",
        "!pip install deepmultilingualpunctuation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nyUYExCeLPYa",
        "outputId": "beabbf1e-c06c-4b64-f3b8-520d3959c9cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: speechrecognition in /usr/local/lib/python3.11/dist-packages (3.14.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from speechrecognition) (4.14.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.7.9)\n",
            "Requirement already satisfied: deepmultilingualpunctuation in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from deepmultilingualpunctuation) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from deepmultilingualpunctuation) (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->deepmultilingualpunctuation) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->deepmultilingualpunctuation) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->deepmultilingualpunctuation) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import  moviepy.editor as mp\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "\n",
        "def extract_audio_form_video(video_path, output_audio_path):\n",
        "  clip = mp.VideoFileClip(video_path)\n",
        "  clip.audio.write_audiofile(output_audio_path)\n",
        "\n",
        "def transcribe_audio(audio_path, output_text_path):\n",
        "  recognizer = sr.Recognizer()\n",
        "  with sr.AudioFile(audio_path) as source:\n",
        "    audio_data = recognizer.record(source)\n",
        "    text = recognizer.recognize_google(audio_data, language=\"en-US\")\n",
        "    with open(output_text_path, \"w\", encoding=\"utf-8\") as text_file:\n",
        "      text_file.write(text)\n",
        "\n",
        "def insert_text_punctuation(input_text_path, output_text_path_punctuation):\n",
        "\n",
        "  with open(input_text_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "  model = PunctuationModel()\n",
        "  text_pontuado = model.restore_punctuation(text)\n",
        "\n",
        "  with open(output_text_path_punctuation, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text_pontuado)\n",
        "\n",
        "extract_audio_form_video(input_video_path, output_audio_path)\n",
        "transcribe_audio(output_audio_path, output_text_path)\n",
        "insert_text_punctuation(output_text_path, output_text_path_punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVSFCsB8Lj8u",
        "outputId": "062c1d8d-8e8a-44cc-c1f8-c95e9ce739f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/output_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorização"
      ],
      "metadata": {
        "id": "BaOg_nY0Oo3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn gensim nltk scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v8_MC-IOteq",
        "outputId": "9cb05205-c489-45e4-f498-16f72df0bc6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFHzajjSbfkH",
        "outputId": "da4abb18-cb78-4599-aa1e-1f01628f7af3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n"
      ],
      "metadata": {
        "id": "sFyl9wBgblW6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import metrics\n",
        "\n",
        "def classify_sentences (input_text, output_text_sentences):\n",
        "  text = []\n",
        "  labels = [\n",
        "      \"technology\",\n",
        "      \"technology\",\n",
        "      \"technology\",\n",
        "      \"reading\",\n",
        "      \"conversation\",\n",
        "      \"movement\",\n",
        "      \"emotion\",\n",
        "      \"emotion\",\n",
        "      \"details\",\n",
        "      \"diversity\",\n",
        "      \"technology\",\n",
        "      \"technology\"\n",
        "  ]\n",
        "\n",
        "  with open(input_text, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "  # Quebra em frases\n",
        "  text = [s.strip() for s in raw_text.split('.') if s.strip()]\n",
        "\n",
        "  print(len(text))\n",
        "  x_train, x_test, y_train, y_test = train_test_split(text[:9], labels[:9], test_size=0.2, random_state=42)\n",
        "\n",
        "  model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "  model.fit(x_train, y_train)\n",
        "\n",
        "  predicted = model.predict(x_test)\n",
        "  with open(output_text_sentences, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"Metrics:\\n\")\n",
        "    f.write(metrics.classification_report(y_test, predicted, zero_division=0))\n",
        "\n",
        "    # Acurácia\n",
        "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
        "    f.write(f\"Acurácia: {accuracy:.2f}\")\n",
        "\n",
        "    test_sentences = [\n",
        "        \"a man focuses intently on a tablet, his brow furrowed in concentration\",\n",
        "        \"two friends laugh loudly while watching a funny video together\",\n",
        "        \"a woman flips through a book, absorbed by its content\",\n",
        "        \"a child waves enthusiastically at the camera, smiling widely\",\n",
        "        \"people move through the space naturally, creating a constant shift in the environment\",\n",
        "        \"a man and woman have a heated discussion, their gestures growing more animated\",\n",
        "        \"a face scanner tracks multiple individuals entering a busy lobby\",\n",
        "        \"subtle facial expressions reveal a range of unspoken thoughts\",\n",
        "        \"visual markers trace the contours of each unique face in the crowd\",\n",
        "        \"the diversity of ages and appearances highlights human uniqueness\"\n",
        "    ]\n",
        "\n",
        "    f.write(\"\\n\\nNew predictions:\\n\")\n",
        "    predictions = model.predict(test_sentences)\n",
        "    for sentence, label in zip(test_sentences, predictions):\n",
        "        f.write(f\"{sentence} ---> {label}\\n\")\n",
        "\n",
        "classify_sentences(output_text_path_punctuation, output_text_path_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf3s4JywO8G1",
        "outputId": "0fc8fa5f-311e-47ec-e831-8c6212b44ece"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumarização\n"
      ],
      "metadata": {
        "id": "gHe5Vl5da4xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBYNEkSma-JG",
        "outputId": "8f2ce78b-3e48-462d-a963-8eed09bb2307"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from transformers import pipeline\n",
        "\n",
        "# Inicialize o modelo de sumarização\n",
        "summarizer = pipeline(\"summarization\", device=-1)\n",
        "\n",
        "def extract_emotion_patterns(text):\n",
        "    \"\"\"\n",
        "    Extrai padrões e tendências das sequências de emoção.\n",
        "    \"\"\"\n",
        "    # Extrair as distribuições gerais\n",
        "    distribution_match = re.search(r\"Overall emotion distribution:(.*?)Emotion sequences:\", text, re.DOTALL)\n",
        "    distributions = {}\n",
        "    if distribution_match:\n",
        "        dist_text = distribution_match.group(1).strip()\n",
        "        for line in dist_text.split('\\n'):\n",
        "            if line.strip():\n",
        "                match = re.search(r'- (\\w+): (\\d+) frames \\((\\d+\\.\\d+)%\\)', line)\n",
        "                if match:\n",
        "                    emotion, frames, percentage = match.groups()\n",
        "                    distributions[emotion] = (int(frames), float(percentage))\n",
        "\n",
        "    # Extrair sequências significativas\n",
        "    sequences = []\n",
        "    seq_pattern = re.compile(r'Sequence \\d+: (\\w+) from frame (\\d+) to (\\d+) \\(duration: (\\d+) frames\\)')\n",
        "    seq_matches = seq_pattern.finditer(text)\n",
        "\n",
        "    for match in seq_matches:\n",
        "        emotion, start, end, duration = match.groups()\n",
        "        sequences.append({\n",
        "            'emotion': emotion,\n",
        "            'start': int(start),\n",
        "            'end': int(end),\n",
        "            'duration': int(duration)\n",
        "        })\n",
        "\n",
        "    # Ordenar sequências por duração (descendente)\n",
        "    sequences.sort(key=lambda x: x['duration'], reverse=True)\n",
        "\n",
        "    # Extrair análise detalhada de frames\n",
        "    frame_analysis = []\n",
        "    analysis_pattern = re.compile(r'From frame (\\d+) to frame (\\d+): predominantly (\\w+)')\n",
        "    analysis_matches = analysis_pattern.finditer(text)\n",
        "\n",
        "    for match in analysis_matches:\n",
        "        start, end, emotion = match.groups()\n",
        "        frame_analysis.append({\n",
        "            'start': int(start),\n",
        "            'end': int(end),\n",
        "            'emotion': emotion\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'distributions': distributions,\n",
        "        'sequences': sequences,\n",
        "        'frame_analysis': frame_analysis\n",
        "    }\n",
        "\n",
        "def create_narrative_chunks(data):\n",
        "    \"\"\"\n",
        "    Cria chunks de texto narrativo a partir dos dados extraídos.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "\n",
        "    # Chunk 1: Visão geral das emoções\n",
        "    overview = \"# Análise Emocional do Vídeo\\n\\n\"\n",
        "    overview += \"## Distribuição Geral de Emoções\\n\\n\"\n",
        "\n",
        "    # Ordenar emoções por percentual\n",
        "    sorted_emotions = sorted(data['distributions'].items(),\n",
        "                            key=lambda x: x[1][1],\n",
        "                            reverse=True)\n",
        "\n",
        "    for emotion, (frames, percentage) in sorted_emotions:\n",
        "        overview += f\"- **{emotion.capitalize()}**: {percentage}% do vídeo ({frames} frames)\\n\"\n",
        "\n",
        "    chunks.append(overview)\n",
        "\n",
        "    # Chunk 2: Principais sequências emocionais\n",
        "    top_sequences = \"## Principais Sequências Emocionais\\n\\n\"\n",
        "    top_sequences += \"As sequências emocionais mais longas identificadas no vídeo são:\\n\\n\"\n",
        "\n",
        "    # Pegar as 10 sequências mais longas\n",
        "    for i, seq in enumerate(data['sequences'][:10]):\n",
        "        emotion = seq['emotion'].capitalize()\n",
        "        duration_sec = seq['duration'] / 30.0  # Assumindo 30 fps, converter para segundos\n",
        "        top_sequences += f\"- **Sequência {i+1}**: {emotion} por {duration_sec:.1f} segundos (frames {seq['start']}-{seq['end']})\\n\"\n",
        "\n",
        "    chunks.append(top_sequences)\n",
        "\n",
        "    # Chunk 3: Padrões e transições\n",
        "    transitions = \"## Padrões e Transições Emocionais\\n\\n\"\n",
        "\n",
        "    # Analisar transições entre emoções\n",
        "    emotion_transitions = defaultdict(int)\n",
        "    prev_emotion = None\n",
        "\n",
        "    for analysis in data['frame_analysis']:\n",
        "        if prev_emotion and prev_emotion != analysis['emotion']:\n",
        "            transition = f\"{prev_emotion} → {analysis['emotion']}\"\n",
        "            emotion_transitions[transition] += 1\n",
        "        prev_emotion = analysis['emotion']\n",
        "\n",
        "    # Pegar as transições mais comuns\n",
        "    common_transitions = sorted(emotion_transitions.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "    transitions += \"As transições emocionais mais frequentes observadas foram:\\n\\n\"\n",
        "    for transition, count in common_transitions:\n",
        "        transitions += f\"- **{transition.capitalize()}**: {count} vezes\\n\"\n",
        "\n",
        "    # Identificar segmentos emocionais do vídeo\n",
        "    video_segments = []\n",
        "    current_segment = {'emotion': data['frame_analysis'][0]['emotion'], 'start': data['frame_analysis'][0]['start']}\n",
        "\n",
        "    for i in range(1, len(data['frame_analysis'])):\n",
        "        if data['frame_analysis'][i]['emotion'] != current_segment['emotion']:\n",
        "            current_segment['end'] = data['frame_analysis'][i-1]['end']\n",
        "            video_segments.append(current_segment)\n",
        "            current_segment = {'emotion': data['frame_analysis'][i]['emotion'], 'start': data['frame_analysis'][i]['start']}\n",
        "\n",
        "    # Adicionar o último segmento\n",
        "    if 'end' not in current_segment:\n",
        "        current_segment['end'] = data['frame_analysis'][-1]['end']\n",
        "        video_segments.append(current_segment)\n",
        "\n",
        "    # Encontrar os 3 segmentos mais longos\n",
        "    video_segments.sort(key=lambda x: x['end'] - x['start'], reverse=True)\n",
        "\n",
        "    transitions += \"\\nOs segmentos emocionais mais longos do vídeo foram:\\n\\n\"\n",
        "    for i, segment in enumerate(video_segments[:3]):\n",
        "        emotion = segment['emotion'].capitalize()\n",
        "        frame_count = segment['end'] - segment['start']\n",
        "        start_time = segment['start'] / 30.0  # Convertendo para segundos\n",
        "        end_time = segment['end'] / 30.0\n",
        "        transitions += f\"- **{emotion}**: {frame_count} frames ({start_time:.1f}s - {end_time:.1f}s do vídeo)\\n\"\n",
        "\n",
        "    chunks.append(transitions)\n",
        "\n",
        "    # Chunk 4: Resumo narrativo\n",
        "    narrative = \"## Narrativa Emocional\\n\\n\"\n",
        "\n",
        "    # Dividir o vídeo em terços para análise narrativa\n",
        "    total_frames = data['frame_analysis'][-1]['end']\n",
        "    first_third = total_frames // 3\n",
        "    second_third = 2 * (total_frames // 3)\n",
        "\n",
        "    # Contar emoções em cada terço\n",
        "    emotions_by_third = [defaultdict(int), defaultdict(int), defaultdict(int)]\n",
        "\n",
        "    for analysis in data['frame_analysis']:\n",
        "        start = analysis['start']\n",
        "        if start < first_third:\n",
        "            section = 0\n",
        "        elif start < second_third:\n",
        "            section = 1\n",
        "        else:\n",
        "            section = 2\n",
        "\n",
        "        emotions_by_third[section][analysis['emotion']] += 1\n",
        "\n",
        "    # Determinar emoção dominante de cada terço\n",
        "    dominant_emotions = []\n",
        "    for third in emotions_by_third:\n",
        "        if third:\n",
        "            dominant = max(third.items(), key=lambda x: x[1])[0]\n",
        "            dominant_emotions.append(dominant)\n",
        "        else:\n",
        "            dominant_emotions.append(\"não identificada\")\n",
        "\n",
        "    narrative += f\"No início do vídeo, a emoção predominante foi **{dominant_emotions[0]}**. \"\n",
        "    narrative += f\"Na parte intermediária, observou-se principalmente **{dominant_emotions[1]}**. \"\n",
        "    narrative += f\"Na parte final, a emoção dominante passou a ser **{dominant_emotions[2]}**.\\n\\n\"\n",
        "\n",
        "    # Adicionar insights sobre picos emocionais\n",
        "    emotional_peaks = []\n",
        "    for emotion in ['happy', 'sad', 'fear', 'surprise', 'angry']:\n",
        "        peaks = [seq for seq in data['sequences'] if seq['emotion'] == emotion and seq['duration'] > 20]\n",
        "        if peaks:\n",
        "            longest_peak = max(peaks, key=lambda x: x['duration'])\n",
        "            emotional_peaks.append({\n",
        "                'emotion': emotion,\n",
        "                'duration': longest_peak['duration'],\n",
        "                'start': longest_peak['start'],\n",
        "                'end': longest_peak['end']\n",
        "            })\n",
        "\n",
        "    if emotional_peaks:\n",
        "        narrative += \"Momentos emocionais significativos incluíram:\\n\\n\"\n",
        "        for peak in emotional_peaks:\n",
        "            emotion = peak['emotion'].capitalize()\n",
        "            start_time = peak['start'] / 30.0\n",
        "            end_time = peak['end'] / 30.0\n",
        "            narrative += f\"- Um pico de **{emotion}** entre {start_time:.1f}s e {end_time:.1f}s\\n\"\n",
        "\n",
        "    chunks.append(narrative)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_emotion_analysis(input_file_path, output_file_path, max_length=150):\n",
        "    \"\"\"\n",
        "    Função principal para resumir a análise de emoções.\n",
        "    \"\"\"\n",
        "    # Ler o arquivo de entrada\n",
        "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # Extrair dados estruturados do texto\n",
        "    data = extract_emotion_patterns(text)\n",
        "\n",
        "    # Criar chunks narrativos\n",
        "    narrative_chunks = create_narrative_chunks(data)\n",
        "\n",
        "    # Processar cada chunk narrativo\n",
        "    processed_chunks = []\n",
        "\n",
        "    for chunk in narrative_chunks:\n",
        "        # Verificar se o chunk precisa ser resumido\n",
        "        if len(chunk.split()) > 100:\n",
        "            try:\n",
        "                # Aplicar o modelo de summarization apenas para chunks longos\n",
        "                result = summarizer(chunk, max_length=max_length, min_length=50, do_sample=False)\n",
        "                if result and len(result) > 0:\n",
        "                    # Preservar títulos de seção e formatar o resumo\n",
        "                    title_match = re.search(r'^(#+\\s.*?)$', chunk, re.MULTILINE)\n",
        "                    title = title_match.group(1) if title_match else \"\"\n",
        "\n",
        "                    summary_text = result[0][\"summary_text\"]\n",
        "                    # Melhorar a formatação do resumo\n",
        "                    summary_text = summary_text.replace(\" . \", \". \")\n",
        "                    summary_text = summary_text.replace(\" , \", \", \")\n",
        "\n",
        "                    processed_text = f\"{title}\\n\\n{summary_text}\" if title else summary_text\n",
        "                    processed_chunks.append(processed_text)\n",
        "                else:\n",
        "                    processed_chunks.append(chunk)\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao resumir chunk: {str(e)[:100]}...\")\n",
        "                processed_chunks.append(chunk)\n",
        "        else:\n",
        "            # Manter chunks curtos intactos\n",
        "            processed_chunks.append(chunk)\n",
        "\n",
        "    # Adicionar conclusão\n",
        "    conclusion = \"\\n\\n## Conclusão\\n\\n\"\n",
        "    conclusion += \"Esta análise emocional revela padrões significativos nas expressões faciais capturadas no vídeo. \"\n",
        "    conclusion += \"As transições entre diferentes estados emocionais fornecem insights sobre a dinâmica do conteúdo apresentado.\"\n",
        "\n",
        "    processed_chunks.append(conclusion)\n",
        "\n",
        "    # Combinar tudo em um texto final\n",
        "    final_text = \"\\n\\n\".join(processed_chunks)\n",
        "\n",
        "    # Salvar o resultado\n",
        "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(final_text)\n",
        "\n",
        "    return final_text\n",
        "\n",
        "# Função para testar sem depender do pipeline transformer\n",
        "def summarize_without_model(input_file_path, output_file_path):\n",
        "    \"\"\"\n",
        "    Versão simplificada que não usa o modelo de transformers.\n",
        "    Útil quando há problemas com o modelo ou para testes rápidos.\n",
        "    \"\"\"\n",
        "    # Ler o arquivo de entrada\n",
        "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # Extrair dados estruturados do texto\n",
        "    data = extract_emotion_patterns(text)\n",
        "\n",
        "    # Criar chunks narrativos (sem resumir)\n",
        "    narrative_chunks = create_narrative_chunks(data)\n",
        "\n",
        "    # Combinar tudo em um texto final\n",
        "    final_text = \"\\n\\n\".join(narrative_chunks)\n",
        "\n",
        "    # Adicionar conclusão\n",
        "    conclusion = \"\\n\\n## Conclusão\\n\\n\"\n",
        "    conclusion += \"Esta análise emocional revela padrões significativos nas expressões faciais capturadas no vídeo. \"\n",
        "    conclusion += \"As transições entre diferentes estados emocionais fornecem insights sobre a dinâmica do conteúdo apresentado.\"\n",
        "\n",
        "    final_text += conclusion\n",
        "\n",
        "    # Salvar o resultado\n",
        "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(final_text)\n",
        "\n",
        "    return final_text\n",
        "\n",
        "# Usando o modelo transformer (pode falhar com o erro de índice)\n",
        "try:\n",
        "    summarize_emotion_analysis(\"output_text_path_video_emotions.txt\",\n",
        "                              \"output_text_path_video_emotions_summarization.txt\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao usar o modelo transformer: {str(e)}\")\n",
        "    print(\"Usando método alternativo...\")\n",
        "\n",
        "    # Versão alternativa sem depender do modelo\n",
        "    summarize_without_model(\"output_text_path_video_emotions.txt\",\n",
        "                           \"output_text_path_video_emotions_summarization.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ApbURx3bMPb",
        "outputId": "b3c8f318-7bd7-4859-c1a0-98b3309df15d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    }
  ]
}